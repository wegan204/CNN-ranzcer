{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.optim.lr_scheduler import StepLR\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn \nimport torch.optim as optim\nimport torchvision\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset\nimport os\n#import natsort\nfrom torch.utils import data\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import TensorDataset, DataLoader\nimport random\nfrom tqdm.auto import tqdm\nseed = 12345\nrandom.seed(seed)\ntorch.manual_seed(seed)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/ranzcr-clip-catheter-line-classification/train.csv')\ntrain_annotations = pd.read_csv('../input/ranzcr-clip-catheter-line-classification/train_annotations.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# labels_dict = {train.iloc[i][0]:torch.Tensor(train.iloc[0][1:-1]) \n#               for i in range(len(train))}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_dict = {}\nfor i in range(len(train)):\n    k = train.iloc[i][0]\n    v = torch.Tensor(train.iloc[0][1:-1])\n    labels_dict[k] = v","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_dict['1.2.826.0.1.3680043.8.498.10000428974990117276582711948006105617']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#the commented things here can change the images to become 3 channel\nclass CustomDataSet(Dataset):\n    def __init__(self, main_dir, transform, labels):\n        self.main_dir = main_dir\n        self.transform = transform\n        all_imgs = os.listdir(main_dir)\n        self.total_imgs = all_imgs#natsort.natsorted(all_imgs)\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.total_imgs)\n\n    def __getitem__(self, idx):\n        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n        image = Image.open(img_loc)#.convert(\"RGB\")\n        tensor_image = self.transform(image)\n        key = os.path.basename(img_loc)[:-4]#this is how we get our ids\n        #input labels as dictionary with id number as the key\n        label = self.labels[key]\n        return tensor_image, label\n\ntrain_transform = transforms.Compose([\n     transforms.Resize((64,64)),\n     transforms.ToTensor(),\n     transforms.Normalize(\n         [0.4826],# 0.4824, 0.4824],\n         [0.2190]),# 0.2142, 0.2142])\n ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images = CustomDataSet('../input/ranzcr-clip-catheter-line-classification/train',train_transform, labels_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_seed = 12345\nvalidation_split = .2\nshuffle_dataset = True\n\ndataset_size = len(images)\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\nif shuffle_dataset :\n    np.random.seed(random_seed)\n    np.random.shuffle(indices)\ntrain_indices, val_indices = indices[split:], indices[:split]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\nval_sampler = torch.utils.data.SubsetRandomSampler(val_indices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 256\ntrain_loader = torch.utils.data.DataLoader(images, batch_size=batch_size, \n                                           sampler=train_sampler, num_workers = 4)\nval_loader = torch.utils.data.DataLoader(images, batch_size=batch_size,\n                                                sampler=val_sampler, num_workers = 4)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class View(nn.Module):\n    def __init__(self, shape):\n        super().__init__()\n        self.shape = shape\n\n    def forward(self, x):\n        return x.view(*self.shape)\n    \n    \n    \nclass ShallowConvnet(nn.Module):\n    def __init__(self, input_channels, num_classes):\n        \"\"\"\n\n        Parameters\n        ----------\n        input_channels : Number of input channels\n        num_classes : Number of classes for the final prediction \n        \"\"\"\n        \n        super().__init__()\n\n        self.input_channels = input_channels\n        self.num_classes = num_classes\n        \n        self.block1 = nn.Sequential(\n            nn.Conv2d(in_channels = self.input_channels, out_channels = 64, kernel_size=5, padding=2),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2)\n        )\n        \n        self.block2 = nn.Sequential(\n            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2)\n        )\n        \n        self.block3 = nn.Sequential(\n            nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 8)\n        )\n        \n        self.fc = nn.Linear(256, self.num_classes)\n        self.sig = nn.Sigmoid()\n\n\n    def forward(self, x):\n        \n        x = self.block1(x)\n\n        x = self.block2(x)\n\n        x = self.block3(x)\n            \n        x = View((-1,256))(x)\n            \n        x = self.fc(x)\n        x = self.sig(x)\n        return x\n\n\n\n        \n    \nclass SimpleConvnet(nn.Module):\n    def __init__(self, input_channels, num_classes):\n        super(SimpleConvnet, self).__init__()\n\n        self.input_channels = input_channels\n        self.num_classes = num_classes\n\n        self.block1 = nn.Sequential(\n            nn.Conv2d(in_channels = self.input_channels, out_channels = 64, kernel_size=5, padding=2),\n            nn.ReLU(),\n        )\n\n        self.block2 = nn.Sequential(\n            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.BatchNorm2d(64),\n            nn.MaxPool2d(kernel_size = 2)\n        )\n\n        self.block3 = nn.Sequential(\n            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.BatchNorm2d(128),\n            nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.BatchNorm2d(128),\n            nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.BatchNorm2d(128),\n            nn.MaxPool2d(kernel_size = 2)\n        )\n\n        self.block4 = nn.Sequential(\n            nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = 1),\n            nn.ReLU(),\n            nn.BatchNorm2d(256),\n            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = 1),\n            nn.ReLU(),\n            nn.BatchNorm2d(256),\n            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = 1),\n            nn.ReLU(),\n            nn.BatchNorm2d(256),\n            nn.MaxPool2d(kernel_size = 16)\n        )\n\n        #final linear layer to project into the correct number of classes\n        self.fc = nn.Linear(256, 11)\n        self.sig = nn.Sigmoid()\n    \n    def forward(self, x):\n       \n        x = self.block1(x)\n\n        x = self.block2(x)\n\n        x = self.block3(x)\n\n        x = self.block4(x)\n\n        x = View((-1,256))(x)\n        x = self.fc(x)\n        x = self.sig(x)\n        output = x\n        \n        return output\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_loop(model, criterion, optimizer,  train_loader, val_loader):\n    \"\"\"\n    Generic training loop\n\n    Parameters\n    ----------\n    model : Object instance of your model class \n    criterion : Loss function \n    optimizer : Instance of optimizer class of your choice \n    train_loader : Training data loader \n    val_loader : Validation data loader\n\n    Returns\n    -------\n    train_losses : List with train loss on dataset per epoch\n    train_accuracies : List with train accuracy on dataset per epoch\n    val_losses : List with validation loss on dataset per epoch\n    val_accuracies : List with validation accuracy on dataset per epoch\n\n    \"\"\"\n    best_val = 0.0\n    train_losses = []\n    val_losses = []\n    train_accuracies = []\n    val_accuracies = []\n    max_patience = 5\n    patience_counter = 0\n    # Training\n    for t in tqdm(range(50)):\n        epoch_t_acc = 0.0 \n        epoch_t_loss = 0.0\n        model.train()       \n        for i, samples in enumerate(train_loader):\n            data, target = samples\n            target = target.long()\n            data, target = data.to(device), target.to(device)\n            \n            y_pred_train = model(data)\n            #y_pred_train = y_pred_train.round()\n\n            loss = criterion(y_pred_train, target)\n#             score, predicted = torch.max(y_pred_train, 1)\n#             acc = (predicted == target).sum().float() / len(target)\n            # for each example in the batch\n            each_ex_acc = (target == y_pred_train.round()).sum(dim=1)/len(target[0])\n            acc = each_ex_acc.sum()/len(target)\n            \n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            epoch_t_acc += acc\n            epoch_t_loss += loss.item()\n\n        train_accuracies.append(epoch_t_acc/len(train_loader))\n        train_losses.append(epoch_t_loss/len(train_loader))\n\n        model.eval()\n\n        v_acc = 0.0\n        v_loss = 0.0\n\n\n        with torch.no_grad():\n        # TODO: Loop over the validation set \n            for i, samples in enumerate(val_loader):\n\n                # TODO: Put the inputs and targets on the write device\n                data, target = samples\n                target = target.long()\n                data, target = data.to(device), target.to(device)\n\n                # TODO: Feed forward to get the logits\n                y_pred_val = model(data)\n\n                # TODO: Compute the loss and accuracy\n                loss = criterion(y_pred_val, target)\n#                 score, predicted = torch.max(y_pred_val, 1)\n#                 acc = (predicted == target).sum().float() / len(target)\n                each_ex_acc = (target == y_pred_val.round()).sum(dim=1)/len(target[0])\n                acc = each_ex_acc.sum()/len(target)\n        \n                v_loss+= loss.item()\n                v_acc += acc\n\n\n        # TODO: Keep track of accuracy and loss\n        val_accuracies.append(v_acc/len(val_loader))\n        val_losses.append(v_loss/len(val_loader))\n\n        if val_accuracies[-1] > best_val:\n            best_val = val_accuracies[-1]\n            patience_counter = 0\n\n      # TODO: Save best model, optimizer, epoch_number\n    \n    \n    \n            torch.save(model.state_dict(), './model_state.pt')\n\n        else:\n            patience_counter += 1    \n            if patience_counter > max_patience: \n                break\n\n        print(\"[EPOCH]: %i, [TRAIN LOSS]: %.6f, [TRAIN ACCURACY]: %.5f\" % (t, train_losses[-1], train_accuracies[-1]))\n        print(\"[EPOCH]: %i, [VAL LOSS]: %.6f, [VAL ACCURACY]: %.5f \\n\" % (t, val_losses[-1] ,val_accuracies[-1]))\n\n    return train_losses, train_accuracies, val_losses, val_accuracies","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TODO : Initialize the model and cast to correct device\ninput_channels = 1\nnum_classes = 11\nmodel_sc = SimpleConvnet(input_channels, num_classes)\nmodel_sc.to(device)\n\n# TODO : Initialize the criterion\ncriterion = torch.nn.MultiLabelSoftMarginLoss()\n# TODO : Initialize the SGD optimizer with lr 1e-3\noptimizer = optim.SGD(model_sc.parameters(), lr = 0.001)\n\n# TODO : Run the training loop using this model\n\ntrain_losses, train_accuracies, val_losses, val_accuracies = train_loop(model_sc, criterion, optimizer, train_loader, val_loader)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mordel = torch.load('./model_state.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mogle = SimpleConvnet(1,11)\nmogle.load_state_dict(mordel)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mordel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nimages = 0\nmean = 0.\nstd = 0.\nfor batch, _ in train_loader:\n    # Rearrange batch to be the shape of [B, C, W * H]\n    batch = batch.view(batch.size(0), batch.size(1), -1)\n    # Update total number of images\n    nimages += batch.size(0)\n    # Compute mean and std here\n    mean += batch.mean(2).sum(0) \n    std += batch.std(2).sum(0)\n\n# Final step\nmean /= nimages\nstd /= nimages\n\nprint(mean)\nprint(std)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}